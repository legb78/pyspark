{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMDYcNwvtYu+CwH7H31j2wH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# Import required libraries\n","from pyspark import SparkContext, SparkConf\n","from pyspark.sql import SparkSession\n","import os\n","\n","# Check if SparkContext already exists and use it (or create a new one if needed)\n","try:\n","    # Try to use the existing SparkContext\n","    sc\n","    print(\"Using existing SparkContext\")\n","except NameError:\n","    # Initialize Spark if no SparkContext exists\n","    conf = SparkConf().setAppName(\"WorldCitiesPop\").setMaster(\"local[*]\")\n","    sc = SparkContext(conf=conf)\n","    print(\"Created new SparkContext\")\n","\n","# Exercise 1: Mise en route\n","print(\"\\n===== Exercise 1: Mise en route =====\")\n","\n","# Check if the worldcitiespop.txt file exists\n","worldcities_path = \"/content/sample_data/worldcitiespop.txt\"\n","\n","if not os.path.exists(worldcities_path):\n","    print(f\"File not found: {worldcities_path}\")\n","    print(\"Please make sure the file is in the correct location.\")\n","else:\n","    # Display the first few lines using terminal command\n","    !head -n 5 {worldcities_path}\n","\n","    # Read the file into an RDD\n","    rddCities = sc.textFile(worldcities_path)\n","    print(\"\\nFirst line of the file:\")\n","    print(rddCities.first())\n","\n","    # Exercise 2: Nettoyage simple worldcitiespop\n","    print(\"\\n===== Exercise 2: Nettoyage simple worldcitiespop =====\")\n","\n","    # Clean the data - keep only lines with population data\n","    # The population is the 5th field (index 4) when splitting by comma\n","    header = rddCities.first()  # Save the header line\n","\n","    # Filter to keep only lines with population data\n","    validCities = rddCities.filter(lambda line: line != header and\n","                                  len(line.split(\",\")) > 4 and\n","                                  line.split(\",\")[4].strip() != \"\" and\n","                                  line.split(\",\")[4].strip().isdigit())\n","\n","    # Count the number of valid cities\n","    validCount = validCities.count()\n","    print(f\"Number of cities with population data: {validCount}\")\n","\n","    # Display some examples of valid cities\n","    print(\"Examples of valid cities:\")\n","    for city in validCities.take(5):\n","        print(city)\n","\n","    # Write the cleaned data to a new file\n","    # First define the output file path\n","    cleaned_file_path = \"/content/cleaned_worldcitiespop.txt\"\n","\n","    # Save as a single file (good for smaller datasets)\n","    validCities.coalesce(1).saveAsTextFile(\"/content/cleaned_data\")\n","\n","    print(f\"\\nCleaned data has been saved to: /content/cleaned_data/part-00000\")\n","    print(\"You can access it in the file browser on the left sidebar of Colab.\")\n","\n","    # Optional: Show the first few lines of the cleaned file\n","    print(\"\\nFirst few lines of the cleaned data:\")\n","    !head -n 5 /content/cleaned_data/part-00000"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uFZFGGvrlf1p","executionInfo":{"status":"ok","timestamp":1743633452864,"user_tz":-120,"elapsed":19188,"user":{"displayName":"Djamel OUAZAR","userId":"18172226209975564172"}},"outputId":"07c2645e-3cbc-41ec-b1d4-c86a21493cd8"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Using existing SparkContext\n","\n","===== Exercise 1: Mise en route =====\n","Country,City,AccentCity,Region,Population,Latitude,Longitude\n","ad,aixas,Aixï¿½s,06,,42.4833333,1.4666667\n","ad,aixirivali,Aixirivali,06,,42.4666667,1.5\n","ad,aixirivall,Aixirivall,06,,42.4666667,1.5\n","ad,aixirvall,Aixirvall,06,,42.4666667,1.5\n","\n","First line of the file:\n","Country,City,AccentCity,Region,Population,Latitude,Longitude\n","\n","===== Exercise 2: Nettoyage simple worldcitiespop =====\n","Number of cities with population data: 47980\n","Examples of valid cities:\n","ad,andorra la vella,Andorra la Vella,07,20430,42.5,1.5166667\n","ad,canillo,Canillo,02,3292,42.5666667,1.6\n","ad,encamp,Encamp,03,11224,42.5333333,1.5833333\n","ad,la massana,La Massana,04,7211,42.55,1.5166667\n","ad,les escaldes,Les Escaldes,08,15854,42.5,1.5333333\n","\n","Cleaned data has been saved to: /content/cleaned_data/part-00000\n","You can access it in the file browser on the left sidebar of Colab.\n","\n","First few lines of the cleaned data:\n","ad,andorra la vella,Andorra la Vella,07,20430,42.5,1.5166667\n","ad,canillo,Canillo,02,3292,42.5666667,1.6\n","ad,encamp,Encamp,03,11224,42.5333333,1.5833333\n","ad,la massana,La Massana,04,7211,42.55,1.5166667\n","ad,les escaldes,Les Escaldes,08,15854,42.5,1.5333333\n"]}]},{"cell_type":"code","source":["# Exercise 3: Statistics on City Populations\n","\n","# Import required libraries\n","from pyspark import SparkContext, SparkConf\n","import numpy as np\n","import math\n","import os\n","import shutil  # For removing directories\n","\n","# Check if SparkContext already exists and use it\n","try:\n","    sc\n","    print(\"Using existing SparkContext\")\n","except NameError:\n","    # Initialize Spark if no SparkContext exists\n","    conf = SparkConf().setAppName(\"CityPopulationStats\").setMaster(\"local[*]\")\n","    sc = SparkContext(conf=conf)\n","    print(\"Created new SparkContext\")\n","\n","# Path to the data file\n","worldcities_path = \"/content/sample_data/worldcitiespop.txt\"\n","\n","# Read the file into an RDD\n","rddCities = sc.textFile(worldcities_path)\n","\n","# Get the header\n","header = rddCities.first()\n","\n","# Filter to keep only lines with valid population data\n","validCities = rddCities.filter(lambda line:\n","                              line != header and\n","                              len(line.split(\",\")) > 4 and\n","                              line.split(\",\")[4].strip() != \"\" and\n","                              line.split(\",\")[4].strip().isdigit())\n","\n","# Extract the population values as integers\n","populations = validCities.map(lambda line: int(line.split(\",\")[4]))\n","\n","# Calculate statistics\n","count = populations.count()\n","min_pop = populations.min()\n","max_pop = populations.max()\n","sum_pop = populations.sum()\n","mean_pop = sum_pop / count\n","variance = populations.map(lambda x: (x - mean_pop) ** 2).sum() / count\n","stdev = math.sqrt(variance)\n","\n","# Print the statistics\n","print(\"\\n===== Population Statistics =====\")\n","print(f\"Count: {count}\")\n","print(f\"Minimum Population: {min_pop}\")\n","print(f\"Maximum Population: {max_pop}\")\n","print(f\"Sum of Populations: {sum_pop}\")\n","print(f\"Average Population: {mean_pop:.2f}\")\n","print(f\"Standard Deviation: {stdev:.2f}\")\n","\n","# Format as in the expected output\n","print(f\"(count: {count}, mean: {mean_pop}, stdev: {stdev}, max: {float(max_pop)}, min: {float(min_pop)})\")\n","\n","# Define the output directory\n","output_dir = \"/content/cleaned_data_ex3\"\n","\n","# Remove the directory if it already exists\n","if os.path.exists(output_dir):\n","    shutil.rmtree(output_dir)  # This will delete the directory and all its contents\n","\n","# Save the clean data\n","validCities.coalesce(1).saveAsTextFile(output_dir)\n","print(f\"\\nCleaned data saved to: {output_dir}/part-00000\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ThEGy8ovm8wf","executionInfo":{"status":"ok","timestamp":1743633724251,"user_tz":-120,"elapsed":54035,"user":{"displayName":"Djamel OUAZAR","userId":"18172226209975564172"}},"outputId":"8a6c0859-afb5-4fcf-e847-208e91f8c103"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Using existing SparkContext\n","\n","===== Population Statistics =====\n","Count: 47980\n","Minimum Population: 7\n","Maximum Population: 31480498\n","Sum of Populations: 2289584999\n","Average Population: 47719.57\n","Standard Deviation: 302885.56\n","(count: 47980, mean: 47719.57063359733, stdev: 302885.5592040371, max: 31480498.0, min: 7.0)\n","\n","Cleaned data saved to: /content/cleaned_data_ex3/part-00000\n"]}]},{"cell_type":"code","source":["# Exercise 4: Population Histograms\n","\n","# Import required libraries\n","from pyspark import SparkContext, SparkConf\n","import numpy as np\n","import math\n","import os\n","import shutil  # For removing directories\n","\n","# Check if SparkContext already exists and use it\n","try:\n","    sc\n","    print(\"Using existing SparkContext\")\n","except NameError:\n","    # Initialize Spark if no SparkContext exists\n","    conf = SparkConf().setAppName(\"CityPopulationHistogram\").setMaster(\"local[*]\")\n","    sc = SparkContext(conf=conf)\n","    print(\"Created new SparkContext\")\n","\n","# Path to the data file\n","worldcities_path = \"/content/sample_data/worldcitiespop.txt\"\n","\n","# Read the file into an RDD\n","rddCities = sc.textFile(worldcities_path)\n","\n","# Get the header\n","header = rddCities.first()\n","\n","# Filter to keep only lines with valid population data\n","validCities = rddCities.filter(lambda line:\n","                              line != header and\n","                              len(line.split(\",\")) > 4 and\n","                              line.split(\",\")[4].strip() != \"\" and\n","                              line.split(\",\")[4].strip().isdigit())\n","\n","# Extract the population values as integers\n","populations = validCities.map(lambda line: int(line.split(\",\")[4]))\n","\n","# Calculate statistics (same as Exercise 3)\n","count = populations.count()\n","min_pop = populations.min()\n","max_pop = populations.max()\n","sum_pop = populations.sum()\n","mean_pop = sum_pop / count\n","variance = populations.map(lambda x: (x - mean_pop) ** 2).sum() / count\n","stdev = math.sqrt(variance)\n","\n","# Print the statistics\n","print(\"\\n===== Population Statistics =====\")\n","print(f\"(count: {count}, mean: {mean_pop}, stdev: {stdev}, max: {float(max_pop)}, min: {float(min_pop)})\")\n","\n","# Calculate the histogram with logarithmic scale\n","# Class 0: [0-10[, Class 1: [10-100[, Class 2: [100-1000[, etc.\n","def get_log_class(population):\n","    if population == 0:\n","        return 0\n","    return int(math.log10(population))\n","\n","# Map each population to its logarithmic class\n","histogram_data = populations.map(lambda pop: (get_log_class(pop), 1))\n","\n","# Count the number of cities in each class\n","histogram = histogram_data.reduceByKey(lambda a, b: a + b)\n","\n","# Sort by class\n","sorted_histogram = histogram.sortByKey().collect()\n","\n","# Print the histogram\n","print(\"\\n===== Population Histogram (Logarithmic Scale) =====\")\n","print(\"Class\\tRange\\t\\tCount\")\n","for class_id, count in sorted_histogram:\n","    range_start = 10 ** class_id if class_id > 0 else 0\n","    range_end = 10 ** (class_id + 1) if class_id >= 0 else 10\n","    print(f\"{class_id}\\t[{range_start}-{range_end}[\\t{count}\")\n","\n","# Format as in the expected output\n","print(sorted_histogram)\n","\n","# Define the output directory\n","output_dir = \"/content/cleaned_data_ex4\"\n","\n","# Remove the directory if it already exists\n","if os.path.exists(output_dir):\n","    shutil.rmtree(output_dir)\n","\n","# Save the clean data\n","validCities.coalesce(1).saveAsTextFile(output_dir)\n","print(f\"\\nCleaned data saved to: {output_dir}/part-00000\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pBJRdri1qRw-","executionInfo":{"status":"ok","timestamp":1743633793632,"user_tz":-120,"elapsed":65154,"user":{"displayName":"Djamel OUAZAR","userId":"18172226209975564172"}},"outputId":"96e8024b-5150-4e0b-fc46-b64ecfc610eb"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Using existing SparkContext\n","\n","===== Population Statistics =====\n","(count: 47980, mean: 47719.57063359733, stdev: 302885.5592040371, max: 31480498.0, min: 7.0)\n","\n","===== Population Histogram (Logarithmic Scale) =====\n","Class\tRange\t\tCount\n","0\t[0-10[\t5\n","1\t[10-100[\t174\n","2\t[100-1000[\t2187\n","3\t[1000-10000[\t20537\n","4\t[10000-100000[\t21550\n","5\t[100000-1000000[\t3248\n","6\t[1000000-10000000[\t269\n","7\t[10000000-100000000[\t10\n","[(0, 5), (1, 174), (2, 2187), (3, 20537), (4, 21550), (5, 3248), (6, 269), (7, 10)]\n","\n","Cleaned data saved to: /content/cleaned_data_ex4/part-00000\n"]}]},{"cell_type":"code","source":["# Exercise 5: Top K Cities by Population\n","\n","# Import required libraries\n","from pyspark import SparkContext, SparkConf\n","import math\n","import os\n","import shutil  # For removing directories\n","\n","# Check if SparkContext already exists and use it\n","try:\n","    sc\n","    print(\"Using existing SparkContext\")\n","except NameError:\n","    # Initialize Spark if no SparkContext exists\n","    conf = SparkConf().setAppName(\"TopCitiesByPopulation\").setMaster(\"local[*]\")\n","    sc = SparkContext(conf=conf)\n","    print(\"Created new SparkContext\")\n","\n","# Path to the data file\n","worldcities_path = \"/content/sample_data/worldcitiespop.txt\"\n","\n","# Read the file into an RDD\n","rddCities = sc.textFile(worldcities_path)\n","\n","# Get the header\n","header = rddCities.first()\n","\n","# Filter to keep only lines with valid population data\n","validCities = rddCities.filter(lambda line:\n","                              line != header and\n","                              len(line.split(\",\")) > 4 and\n","                              line.split(\",\")[4].strip() != \"\" and\n","                              line.split(\",\")[4].strip().isdigit())\n","\n","# Extract the population values as integers along with the full line\n","city_with_pop = validCities.map(lambda line: (int(line.split(\",\")[4]), line))\n","\n","# Calculate statistics for populations\n","populations = city_with_pop.map(lambda x: x[0])\n","count = populations.count()\n","min_pop = populations.min()\n","max_pop = populations.max()\n","sum_pop = populations.sum()\n","mean_pop = sum_pop / count\n","variance = populations.map(lambda x: (x - mean_pop) ** 2).sum() / count\n","stdev = math.sqrt(variance)\n","\n","# Print the statistics\n","print(\"\\n===== Population Statistics =====\")\n","print(f\"(count: {count}, mean: {mean_pop}, stdev: {stdev}, max: {float(max_pop)}, min: {float(min_pop)})\")\n","\n","# Calculate the histogram with logarithmic scale\n","def get_log_class(population):\n","    if population == 0:\n","        return 0\n","    return int(math.log10(population))\n","\n","histogram_data = populations.map(lambda pop: (get_log_class(pop), 1))\n","histogram = histogram_data.reduceByKey(lambda a, b: a + b)\n","sorted_histogram = histogram.sortByKey().collect()\n","print(sorted_histogram)\n","\n","# Get the top 10 cities by population\n","top_cities = city_with_pop.sortByKey(ascending=False).take(10)\n","\n","# Print the top 10 cities\n","print(\"\\n===== Top 10 Cities by Population =====\")\n","for i, (pop, city_line) in enumerate(top_cities, 1):\n","    fields = city_line.split(\",\")\n","    country_code = fields[0]\n","    city_name = fields[1]\n","    accent_city = fields[2]\n","    region = fields[3]\n","    population = fields[4]\n","    latitude = fields[5] if len(fields) > 5 else \"N/A\"\n","    longitude = fields[6] if len(fields) > 6 else \"N/A\"\n","\n","    print(f\"{i}. {country_code},{city_name},{accent_city},{region},{population},{latitude},{longitude}\")\n","\n","# Define the output directory\n","output_dir = \"/content/cleaned_data_ex5\"\n","\n","# Remove the directory if it already exists\n","if os.path.exists(output_dir):\n","    shutil.rmtree(output_dir)\n","\n","# Save the clean data\n","validCities.coalesce(1).saveAsTextFile(output_dir)\n","print(f\"\\nCleaned data saved to: {output_dir}/part-00000\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sXrb5F6GqU1g","executionInfo":{"status":"ok","timestamp":1743633881133,"user_tz":-120,"elapsed":85880,"user":{"displayName":"Djamel OUAZAR","userId":"18172226209975564172"}},"outputId":"5db5a015-d51b-45bb-da3c-c21f0ed3e8bc"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Using existing SparkContext\n","\n","===== Population Statistics =====\n","(count: 47980, mean: 47719.57063359733, stdev: 302885.5592040371, max: 31480498.0, min: 7.0)\n","[(0, 5), (1, 174), (2, 2187), (3, 20537), (4, 21550), (5, 3248), (6, 269), (7, 10)]\n","\n","===== Top 10 Cities by Population =====\n","1. jp,tokyo,Tokyo,40,31480498,35.685,139.751389\n","2. cn,shanghai,Shanghai,23,14608512,31.045556,121.399722\n","3. in,bombay,Bombay,16,12692717,18.975,72.825833\n","4. pk,karachi,Karachi,05,11627378,24.9056,67.0822\n","5. in,delhi,Delhi,07,10928270,28.666667,77.216667\n","6. in,new delhi,New Delhi,07,10928270,28.6,77.2\n","7. ph,manila,Manila,D9,10443877,14.6042,120.9822\n","8. ru,moscow,Moscow,48,10381288,55.752222,37.615556\n","9. kr,seoul,Seoul,11,10323448,37.5985,126.9783\n","10. br,sao paulo,Sï¿½o Paulo,27,10021437,-23.473293,-46.665803\n","\n","Cleaned data saved to: /content/cleaned_data_ex5/part-00000\n"]}]},{"cell_type":"code","source":["# Exercise 6: Re-cleaning - Removing Duplicates\n","\n","# Import required libraries\n","from pyspark import SparkContext, SparkConf\n","import math\n","import os\n","import shutil  # For removing directories\n","\n","# Check if SparkContext already exists and use it\n","try:\n","    sc\n","    print(\"Using existing SparkContext\")\n","except NameError:\n","    # Initialize Spark if no SparkContext exists\n","    conf = SparkConf().setAppName(\"CitiesDeduplication\").setMaster(\"local[*]\")\n","    sc = SparkContext(conf=conf)\n","    print(\"Created new SparkContext\")\n","\n","# Path to the data file\n","worldcities_path = \"/content/sample_data/worldcitiespop.txt\"\n","\n","# Read the file into an RDD\n","rddCities = sc.textFile(worldcities_path)\n","\n","# Get the header\n","header = rddCities.first()\n","\n","# Filter to keep only lines with valid population data\n","validCities = rddCities.filter(lambda line:\n","                              line != header and\n","                              len(line.split(\",\")) > 4 and\n","                              line.split(\",\")[4].strip() != \"\" and\n","                              line.split(\",\")[4].strip().isdigit())\n","\n","# Function to determine if two locations are close enough to be considered the same city\n","# This function creates a proximity-based key for cities\n","def create_location_key(fields):\n","    try:\n","        # Use country code and city name as the primary key components\n","        country = fields[0]\n","        city_name = fields[1].lower()  # Normalize city name to lowercase\n","\n","        # If we have coordinates, add them (rounded) to make the key more specific\n","        if len(fields) >= 7 and fields[5] and fields[6]:\n","            # Round coordinates to 1 decimal place (approx 11km resolution)\n","            try:\n","                lat = round(float(fields[5]), 1)\n","                lon = round(float(fields[6]), 1)\n","                return f\"{country}_{city_name}_{lat}_{lon}\"\n","            except ValueError:\n","                pass\n","\n","        # If no valid coordinates, use country and city name\n","        return f\"{country}_{city_name}\"\n","    except:\n","        # Fallback in case of any parsing errors\n","        return fields[0] + \"_\" + fields[1] if len(fields) > 1 else fields[0]\n","\n","# Parse cities and create a key based on location\n","parsed_cities = validCities.map(lambda line:\n","                               (create_location_key(line.split(\",\")),\n","                                (int(line.split(\",\")[4]), line)))\n","\n","# Group by location and take the city with the highest population for each location\n","deduplicated_cities = parsed_cities.reduceByKey(lambda a, b: a if a[0] >= b[0] else b)\n","\n","# Extract the city information (without the location key)\n","clean_cities = deduplicated_cities.map(lambda x: x[1][1])\n","\n","# Extract the population values for statistics\n","populations = clean_cities.map(lambda line: int(line.split(\",\")[4]))\n","\n","# Calculate statistics for populations\n","count = populations.count()\n","min_pop = populations.min()\n","max_pop = populations.max()\n","sum_pop = populations.sum()\n","mean_pop = sum_pop / count\n","variance = populations.map(lambda x: (x - mean_pop) ** 2).sum() / count\n","stdev = math.sqrt(variance)\n","\n","# Print the statistics (after deduplication)\n","print(\"\\n===== Population Statistics (After Deduplication) =====\")\n","print(f\"(count: {count}, mean: {mean_pop}, stdev: {stdev}, max: {float(max_pop)}, min: {float(min_pop)})\")\n","\n","# Calculate the histogram with logarithmic scale\n","def get_log_class(population):\n","    if population == 0:\n","        return 0\n","    return int(math.log10(population))\n","\n","histogram_data = populations.map(lambda pop: (get_log_class(pop), 1))\n","histogram = histogram_data.reduceByKey(lambda a, b: a + b)\n","sorted_histogram = histogram.sortByKey().collect()\n","print(sorted_histogram)\n","\n","# Get the top 20 cities by population (to match expected output)\n","city_with_pop = clean_cities.map(lambda line: (int(line.split(\",\")[4]), line))\n","top_cities = city_with_pop.sortByKey(ascending=False).take(20)\n","\n","# Print the top 20 cities in the format from the expected output\n","print(\"\\n===== Top 20 Cities by Population (After Deduplication) =====\")\n","for pop, city_line in top_cities:\n","    fields = city_line.split(\",\")\n","    if len(fields) >= 7:\n","        country_code = fields[0]\n","        city_name = fields[1]\n","        accent_city = fields[2]\n","        region = fields[3]\n","        population = fields[4]\n","        latitude = fields[5]\n","        longitude = fields[6]\n","\n","        print(f\"{country_code},{city_name},{accent_city},{region},{population},{latitude},{longitude}\")\n","\n","# Define the output directory\n","output_dir = \"/content/deduplicated_data_ex6\"\n","\n","# Remove the directory if it already exists\n","if os.path.exists(output_dir):\n","    shutil.rmtree(output_dir)\n","\n","# Save the deduplicated data\n","clean_cities.coalesce(1).saveAsTextFile(output_dir)\n","print(f\"\\nDeduplicated data saved to: {output_dir}/part-00000\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xc0_tv_bqXCm","executionInfo":{"status":"ok","timestamp":1743633904394,"user_tz":-120,"elapsed":23275,"user":{"displayName":"Djamel OUAZAR","userId":"18172226209975564172"}},"outputId":"2ea0d89a-6fe5-4ad7-f3a5-0acf3180d91d"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Using existing SparkContext\n","\n","===== Population Statistics (After Deduplication) =====\n","(count: 47932, mean: 47706.636923141115, stdev: 302954.5879980082, max: 31480498.0, min: 7.0)\n","[(0, 5), (1, 174), (2, 2186), (3, 20506), (4, 21540), (5, 3243), (6, 268), (7, 10)]\n","\n","===== Top 20 Cities by Population (After Deduplication) =====\n","jp,tokyo,Tokyo,40,31480498,35.685,139.751389\n","cn,shanghai,Shanghai,23,14608512,31.045556,121.399722\n","in,bombay,Bombay,16,12692717,18.975,72.825833\n","pk,karachi,Karachi,05,11627378,24.9056,67.0822\n","in,delhi,Delhi,07,10928270,28.666667,77.216667\n","in,new delhi,New Delhi,07,10928270,28.6,77.2\n","ph,manila,Manila,D9,10443877,14.6042,120.9822\n","ru,moscow,Moscow,48,10381288,55.752222,37.615556\n","kr,seoul,Seoul,11,10323448,37.5985,126.9783\n","br,sao paulo,Sï¿½o Paulo,27,10021437,-23.473293,-46.665803\n","tr,istanbul,Istanbul,34,9797536,41.018611,28.964722\n","ng,lagos,Lagos,05,8789133,6.453056,3.395833\n","mx,mexico,Mexico,09,8720916,19.434167,-99.138611\n","id,jakarta,Jakarta,04,8540306,-6.174444,106.829444\n","us,new york,New York,NY,8107916,40.7141667,-74.0063889\n","cd,kinshasa,Kinshasa,06,7787832,-4.3,15.3\n","eg,cairo,Cairo,11,7734602,30.05,31.25\n","pe,lima,Lima,15,7646786,-12.05,-77.05\n","cn,peking,Peking,22,7480601,39.928889,116.388333\n","gb,london,London,H9,7421228,51.514125,-.093689\n","\n","Deduplicated data saved to: /content/deduplicated_data_ex6/part-00000\n"]}]}]}